# 本仓库记录python爬虫的学习过程
## other
- [ProxyPool](https://github.com/BigOrange128/Python-Spider/tree/master/ProxyPool)
    
      一个完整代理池。爬虫获取，mysql存储，flask接口
- [sql](https://github.com/BigOrange128/Python-Spider/blob/master/sql.py)

      对mysql数据库的基本操作(增删改查)
- [头条](https://github.com/BigOrange128/Python-Spider/blob/master/%E5%A4%B4%E6%9D%A1.py)

      通过关键词爬取头条图片，保存为图片格式
- [淘宝商品-GET](https://github.com/BigOrange128/Python-Spider/blob/master/%E6%B7%98%E5%AE%9D%E5%95%86%E5%93%81-GET.py)
> 因淘宝限制不登录不能看商品列表，爬取前要在代码get_paga函数内的headers内加入cookie的值
 
      request加re通过关键词爬取淘宝商品信息，保存为CSV
- [淘宝商品](https://github.com/BigOrange128/Python-Spider/blob/master/%E6%B7%98%E5%AE%9D%E5%95%86%E5%93%81.py)
> 代码失效，淘宝限制不登录不能查看商品列表，需要改代码加入cookie信息
 
      驱动chrome浏览器根据关键词爬取淘宝商品信息，mysql存储
- [猫眼top100](https://github.com/BigOrange128/Python-Spider/blob/master/%E7%8C%AB%E7%9C%BCTOP100.py)
    
      requests加re爬取猫眼电影TOP100榜单
## scrapy
- [images360](https://github.com/BigOrange128/Python-Spider/tree/master/images360)
        
      利用scrapy框架爬取360图片，mysql存储
- [tutorial](https://github.com/BigOrange128/Python-Spider/tree/master/tutorial)
      
      利用scrapy框架爬取Quotes to Scrape，mongodb存储
## pyspider
- [智联招聘](https://github.com/BigOrange128/Python-Spider/blob/master/%E6%99%BA%E8%81%94%E6%8B%9B%E8%81%98.py)

      pyspider框架通过关键词爬取智联招聘
- [去哪儿旅游攻略](https://github.com/BigOrange128/Python-Spider/blob/master/%E5%8E%BB%E5%93%AA%E5%84%BF%E6%97%85%E6%B8%B8%E6%94%BB%E7%95%A5.py)
    
      pyspider框架爬取去哪儿旅游攻略文章

目前在阅读崔庆才写的《Python3网络爬虫开发实战》，仓库内的部分项目代码从书中参考。
    
    

